{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executiomn Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these characters are used as part of the compression algorithm\n",
    "\n",
    "gsm = list(r'@£$¥èéùìòÇØøÅå_^{}[~]|€ӔӕßÉ!#¤%&()*+,-./:;<?¡§¿äöñüàÀÁÂÃÄÈÊËÌÍÎÏÐÑÒÓÔÕÖÙÚÛÜÝÞþáâãçêëíîïðóôõúûýabcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "gsm.append(\"\\\\\")\n",
    "range_list = [0, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, 1000]\n",
    "for i in range_list:\n",
    "    gsm.append(\"Num\"+str(i))\n",
    "\n",
    "gsm.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the encode function compresses an ECG segment(in numerical format) to an alphanumeric value\n",
    "from queue import Queue\n",
    "import math\n",
    "def encode(lines):\n",
    "    \n",
    "    q = Queue()\n",
    "    for j in map(int,lines.split(',')):\n",
    "        q.put(j)\n",
    "    \n",
    "    print(q)\n",
    "    \n",
    "    noOfSmpl = 1\n",
    "    intDiff = []\n",
    "    endOfEcg = False\n",
    "    rrOn = True\n",
    "    rrCount = 0\n",
    "    ecgSmpl1 = q.get()\n",
    "    rrComp1 = 0\n",
    "    encSB = []\n",
    "    rrSB = []\n",
    "    gsm = list(\n",
    "        r'@£$¥èéùìòÇØøÅå_^{}[~]|€ӔӕßÉ!#¤%&()*+,-./:;<?¡§¿äöñüàÀÁÂÃÄÈÊËÌÍÎÏÐÑÒÓÔÕÖÙÚÛÜÝÞþáâãçêëíîïðóôõúûýabcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "    gsm.append(\"\\\\\")\n",
    "\n",
    "\n",
    "    intHrv = 0\n",
    "    while endOfEcg != True and not q.empty():\n",
    "\n",
    "        intDiff = [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        for i in range(0, 8):\n",
    "            ecgSmpl2 = q.get()\n",
    "            noOfSmpl = noOfSmpl + 1\n",
    "            diff = ecgSmpl2 - ecgSmpl1\n",
    "\n",
    "            try:\n",
    "                if (math.ceil(diff) - diff) > 0.5:\n",
    "                    intDiff[i] = int(math.floor(diff))  # there was an (int) here\n",
    "                else:\n",
    "                    intDiff[i] = int(math.ceil(diff))\n",
    "            except:\n",
    "                print(\"ERROR\", intDiff[i], math.floor(diff))\n",
    "\n",
    "            ecgSmpl1 = ecgSmpl2\n",
    "\n",
    "        if q.empty():\n",
    "            endOfEcg = True\n",
    "\n",
    "        # intDiff is a list of 8 elements\n",
    "        signVal = 0\n",
    "\n",
    "        for i in range(0, 8):\n",
    "            if intDiff[i] <= -1:\n",
    "                if i == 0:\n",
    "                    signVal = signVal + 1\n",
    "                elif i == 1:\n",
    "                    signVal = signVal + 2\n",
    "                elif i == 2:\n",
    "                    signVal = signVal + 4\n",
    "                elif i == 3:\n",
    "                    signVal = signVal + 8\n",
    "                elif i == 4:\n",
    "                    signVal = signVal + 16\n",
    "                elif i == 5:\n",
    "                    signVal = signVal + 32\n",
    "                elif i == 6:\n",
    "                    signVal = signVal + 64\n",
    "                elif i == 7:\n",
    "                    encSB.append('')\n",
    "\n",
    "                intDiff[i] = abs(intDiff[i])\n",
    "\n",
    "        encSB.append(gsm[signVal])\n",
    "\n",
    "\n",
    "        # for q = 7\n",
    "        for i in range(0, 7, 2):\n",
    "            # compresses two single digits as one\n",
    "            if (intDiff[i] < 10) and (intDiff[i + 1] < 10):\n",
    "                join = intDiff[i] * 10 + intDiff[i + 1]\n",
    "                encSB.append(gsm[join])\n",
    "            # compresses all values less than 147\n",
    "            elif (intDiff[i] < 47) and (intDiff[i + 1] < 47):\n",
    "                encSB.append(gsm[intDiff[i] + 100])\n",
    "                encSB.append(gsm[intDiff[i + 1] + 100])\n",
    "            else:\n",
    "                encSB.append(str(intDiff[i]))\n",
    "                encSB.append('\"')\n",
    "                encSB.append(str(intDiff[i + 1]))\n",
    "                encSB.append('\"')\n",
    "                # rr detection proceeding\n",
    "                if rrOn == True:\n",
    "                    if (rrComp1 < intDiff[i]) and (intDiff[i] < intDiff[i + 1]):\n",
    "                        rrComp1 = intDiff[i + 1]\n",
    "                    else:\n",
    "                        if rrComp1 < intDiff[i]:\n",
    "                            rrCount = rrCount - 1\n",
    "                        rrVal = float(rrCount)\n",
    "                        rrVal = rrVal / 360\n",
    "                        rrSB.append(rrVal)\n",
    "                        rrCount = 0\n",
    "                        rrOn = False\n",
    "                        intHrv = intHrv + 1\n",
    "\n",
    "    str_encSB = ''.join(encSB)\n",
    "\n",
    "    return str_encSB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this function derives the features from a compressed ECG segment\n",
    "\n",
    "def compress(segment):\n",
    "    i = 0\n",
    "    range_list = [0, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, 1000]\n",
    "    alpha_count = {}\n",
    "    while i < len(segment):\n",
    "\n",
    "        if segment[i].isdigit():\n",
    "\n",
    "            s = ''\n",
    "            while (segment[i] != '\"'):\n",
    "                s = s + segment[i]\n",
    "                i = i + 1\n",
    "\n",
    "            for g in range(len(range_list)):\n",
    "                if int(s) <= range_list[g]:\n",
    "                    t = \"Num\" + str(g)\n",
    "                    break\n",
    "\n",
    "            if t not in alpha_count.keys():\n",
    "                alpha_count[t] = 1\n",
    "            else:\n",
    "                alpha_count[t] = alpha_count[t] + 1\n",
    "\n",
    "\n",
    "        else:\n",
    "            s = segment[i]\n",
    "            if s not in alpha_count.keys():\n",
    "                alpha_count[s] = 1\n",
    "            else:\n",
    "                alpha_count[s] = alpha_count[s] + 1\n",
    "\n",
    "        i = i + 1\n",
    "\n",
    "\n",
    "    output = []\n",
    "    for val in gsm:\n",
    "        if val in alpha_count.keys():\n",
    "            output.append(alpha_count[val])\n",
    "        else:\n",
    "            output.append(0)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The main program starts from here\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import SparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#defining a spark session\n",
    "spark = SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all the data is loaded in an RDD at once\n",
    "rdd = sc.textFile(r'C:\\Users\\Shweta\\PycharmProjects\\untitled\\new_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3,4,5,9,8,8,7,3,3,2,3,2,2,1,2,1,0,1,1,2,2,1,2,2,2,1,2,1,1,3,3,0,6,13,37,55,77,98,110,112,103,85,56,18,15,45,93,111,116,114,102,85,65,36,21,12,8,7,6,5,5,3,4,3,3,1,1,2,5,5,5,5,6,7,7,8,9,8,8,8,7,6,6,5,4,5,7,6,8,7,8,10,12,15,13,12,13']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is what one line of the data looks like\n",
    "rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kø;£:îøØøø{ØØø@ÕøØ],@nEyCBs¤^yJSj30\"48\"ylHisxAJvaðøØ|Ø£]å@£{ØøØ£þØøÅÅdø€(ø',\n",
       " 'Ð@££Ø{@Ø]|Ò£@£]¥|Ø|$@ìyMsp|_}PKkTNpH*,rQIi^;|Å£,Ø]£ØÅ£ø@@ò£øø@øÅ$ø£',\n",
       " 'c&ÉÒ<E$<|%,@øøÃÍüÅ|ӕ@lFuyCGulì24\"53\"Mn49\"54\"JjbzV\\\\Hänq¥§¥ø@a||Ø]$øØ@£òØ£øӔÀ*|ÃØ',\n",
       " 'A$£€ø@£&]@âøÅ@]òØÅ@€@mrrxCECu_gu46\"48\"3\"57\"76\"33\"ÏhH48\"69\"KxüDÅum€ÊáÉøØÅßå£|Åìø%$|ù£]Å]',\n",
       " 'c@ø£|{(@|Ø§Øøøå¿*|Å#@yswxvwtn^lC61\"29\"70\"70\"SnH28\"51\"60\"38\"íØ-ØØ£@þÅøÅø¡ê;$£;Ø£øø@ØØ]*']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now the encode function is mapped to each line of the RDD\n",
    "data1 = rdd.map(encode)\n",
    "data1.take(5)             #we have shown 5 lines of compressed ECG signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 3, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 2, 0, 0, 1, 0, 1, 3, 0, 2, 1, 0, 0, 0, 4, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 1, 0, 0, 1]\n",
      "[0, 0, 2, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 5, 1, 0, 0, 9, 0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 2, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 2, 0, 4, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 1, 1, 0, 5, 0, 0, 0, 2, 0, 2, 1, 0, 1, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0]\n",
      "[0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 1, 0, 2, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 3, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 4, 1, 0, 0, 1, 0, 0, 0, 0, 3]\n",
      "[0, 1, 1, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 0, 2, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 1, 0, 1, 2, 1, 1, 0, 1, 3, 0, 0, 1, 4, 0, 0, 1, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# now features are derived from each line of the RDD\n",
    "data2 = data1.map(compress)\n",
    "temp = data2.take(5)           #we have shown features derived from 5 ECG segments\n",
    "\n",
    "for i in temp:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '#', '$', '%', '&', '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'Num0', 'Num100', 'Num1000', 'Num150', 'Num200', 'Num250', 'Num300', 'Num350', 'Num400', 'Num450', 'Num50', 'Num500', 'Num550', 'Num600', 'Num650', 'Num700', 'Num750', 'Num800', 'Num850', 'Num900', 'Num950', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', '¡', '£', '¤', '¥', '§', '¿', 'À', 'Á', 'Â', 'Ã', 'Ä', 'Å', 'Ç', 'È', 'É', 'Ê', 'Ë', 'Ì', 'Í', 'Î', 'Ï', 'Ð', 'Ñ', 'Ò', 'Ó', 'Ô', 'Õ', 'Ö', 'Ø', 'Ù', 'Ú', 'Û', 'Ü', 'Ý', 'Þ', 'ß', 'à', 'á', 'â', 'ã', 'ä', 'å', 'ç', 'è', 'é', 'ê', 'ë', 'ì', 'í', 'î', 'ï', 'ð', 'ñ', 'ò', 'ó', 'ô', 'õ', 'ö', 'ø', 'ù', 'ú', 'û', 'ü', 'ý', 'þ', 'Ӕ', 'ӕ', '€']\n"
     ]
    }
   ],
   "source": [
    "#these are the indivisual features we shall be looking for\n",
    "keys = gsm\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now we create a DataFrame from our RDD\n",
    "a = sqlContext.createDataFrame(data2, ['x'+str(i) for i in range(0,len(keys))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(x0,LongType,true),StructField(x1,LongType,true),StructField(x2,LongType,true),StructField(x3,LongType,true),StructField(x4,LongType,true),StructField(x5,LongType,true),StructField(x6,LongType,true),StructField(x7,LongType,true),StructField(x8,LongType,true),StructField(x9,LongType,true),StructField(x10,LongType,true),StructField(x11,LongType,true),StructField(x12,LongType,true),StructField(x13,LongType,true),StructField(x14,LongType,true),StructField(x15,LongType,true),StructField(x16,LongType,true),StructField(x17,LongType,true),StructField(x18,LongType,true),StructField(x19,LongType,true),StructField(x20,LongType,true),StructField(x21,LongType,true),StructField(x22,LongType,true),StructField(x23,LongType,true),StructField(x24,LongType,true),StructField(x25,LongType,true),StructField(x26,LongType,true),StructField(x27,LongType,true),StructField(x28,LongType,true),StructField(x29,LongType,true),StructField(x30,LongType,true),StructField(x31,LongType,true),StructField(x32,LongType,true),StructField(x33,LongType,true),StructField(x34,LongType,true),StructField(x35,LongType,true),StructField(x36,LongType,true),StructField(x37,LongType,true),StructField(x38,LongType,true),StructField(x39,LongType,true),StructField(x40,LongType,true),StructField(x41,LongType,true),StructField(x42,LongType,true),StructField(x43,LongType,true),StructField(x44,LongType,true),StructField(x45,LongType,true),StructField(x46,LongType,true),StructField(x47,LongType,true),StructField(x48,LongType,true),StructField(x49,LongType,true),StructField(x50,LongType,true),StructField(x51,LongType,true),StructField(x52,LongType,true),StructField(x53,LongType,true),StructField(x54,LongType,true),StructField(x55,LongType,true),StructField(x56,LongType,true),StructField(x57,LongType,true),StructField(x58,LongType,true),StructField(x59,LongType,true),StructField(x60,LongType,true),StructField(x61,LongType,true),StructField(x62,LongType,true),StructField(x63,LongType,true),StructField(x64,LongType,true),StructField(x65,LongType,true),StructField(x66,LongType,true),StructField(x67,LongType,true),StructField(x68,LongType,true),StructField(x69,LongType,true),StructField(x70,LongType,true),StructField(x71,LongType,true),StructField(x72,LongType,true),StructField(x73,LongType,true),StructField(x74,LongType,true),StructField(x75,LongType,true),StructField(x76,LongType,true),StructField(x77,LongType,true),StructField(x78,LongType,true),StructField(x79,LongType,true),StructField(x80,LongType,true),StructField(x81,LongType,true),StructField(x82,LongType,true),StructField(x83,LongType,true),StructField(x84,LongType,true),StructField(x85,LongType,true),StructField(x86,LongType,true),StructField(x87,LongType,true),StructField(x88,LongType,true),StructField(x89,LongType,true),StructField(x90,LongType,true),StructField(x91,LongType,true),StructField(x92,LongType,true),StructField(x93,LongType,true),StructField(x94,LongType,true),StructField(x95,LongType,true),StructField(x96,LongType,true),StructField(x97,LongType,true),StructField(x98,LongType,true),StructField(x99,LongType,true),StructField(x100,LongType,true),StructField(x101,LongType,true),StructField(x102,LongType,true),StructField(x103,LongType,true),StructField(x104,LongType,true),StructField(x105,LongType,true),StructField(x106,LongType,true),StructField(x107,LongType,true),StructField(x108,LongType,true),StructField(x109,LongType,true),StructField(x110,LongType,true),StructField(x111,LongType,true),StructField(x112,LongType,true),StructField(x113,LongType,true),StructField(x114,LongType,true),StructField(x115,LongType,true),StructField(x116,LongType,true),StructField(x117,LongType,true),StructField(x118,LongType,true),StructField(x119,LongType,true),StructField(x120,LongType,true),StructField(x121,LongType,true),StructField(x122,LongType,true),StructField(x123,LongType,true),StructField(x124,LongType,true),StructField(x125,LongType,true),StructField(x126,LongType,true),StructField(x127,LongType,true),StructField(x128,LongType,true),StructField(x129,LongType,true),StructField(x130,LongType,true),StructField(x131,LongType,true),StructField(x132,LongType,true),StructField(x133,LongType,true),StructField(x134,LongType,true),StructField(x135,LongType,true),StructField(x136,LongType,true),StructField(x137,LongType,true),StructField(x138,LongType,true),StructField(x139,LongType,true),StructField(x140,LongType,true),StructField(x141,LongType,true),StructField(x142,LongType,true),StructField(x143,LongType,true),StructField(x144,LongType,true),StructField(x145,LongType,true),StructField(x146,LongType,true),StructField(x147,LongType,true),StructField(x148,LongType,true),StructField(x149,LongType,true),StructField(x150,LongType,true),StructField(x151,LongType,true),StructField(x152,LongType,true),StructField(x153,LongType,true),StructField(x154,LongType,true),StructField(x155,LongType,true),StructField(x156,LongType,true),StructField(x157,LongType,true),StructField(x158,LongType,true),StructField(x159,LongType,true),StructField(x160,LongType,true),StructField(x161,LongType,true),StructField(x162,LongType,true),StructField(x163,LongType,true),StructField(x164,LongType,true),StructField(x165,LongType,true),StructField(x166,LongType,true),StructField(x167,LongType,true)))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is the schema of the DataFrame\n",
    "a.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We take the class of the input features in a list\n",
    "fz = open(r'C:\\Users\\Shweta\\PycharmProjects\\untitled\\new_output_class.txt', 'r')\n",
    "cls = fz.read()\n",
    "fz.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# c = 0\n",
    "# for i in cls.split(','):\n",
    "#     if i != '':\n",
    "#         c += 1\n",
    "# print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we create another DataFrame consisting of only class column\n",
    "b = sqlContext.createDataFrame([(int(i),) for i in cls.split(',') if i != ''], ['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(class,LongType,true)))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we consider the schema of the class column\n",
    "b.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now we join the two dataframes(for features and class) togeather in the final dataFrame\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "a = a.withColumn(\"row_idx\", monotonically_increasing_id())\n",
    "b = b.withColumn(\"row_idx\", monotonically_increasing_id())\n",
    "final_df = b.join(a, b.row_idx == a.row_idx).drop(\"row_idx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "|class| x0| x1| x2| x3| x4| x5| x6| x7| x8| x9|x10|x11|x12|x13|x14|x15|x16|x17|x18|x19|x20|x21|x22|x23|x24|x25|x26|x27|x28|x29|x30|x31|x32|x33|x34|x35|x36|x37|x38|x39|x40|x41|x42|x43|x44|x45|x46|x47|x48|x49|x50|x51|x52|x53|x54|x55|x56|x57|x58|x59|x60|x61|x62|x63|x64|x65|x66|x67|x68|x69|x70|x71|x72|x73|x74|x75|x76|x77|x78|x79|x80|x81|x82|x83|x84|x85|x86|x87|x88|x89|x90|x91|x92|x93|x94|x95|x96|x97|x98|x99|x100|x101|x102|x103|x104|x105|x106|x107|x108|x109|x110|x111|x112|x113|x114|x115|x116|x117|x118|x119|x120|x121|x122|x123|x124|x125|x126|x127|x128|x129|x130|x131|x132|x133|x134|x135|x136|x137|x138|x139|x140|x141|x142|x143|x144|x145|x146|x147|x148|x149|x150|x151|x152|x153|x154|x155|x156|x157|x158|x159|x160|x161|x162|x163|x164|x165|x166|x167|\n",
      "+-----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "|    1|  1|  0|  2|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  1|  0|  6|  1|  1|  0|  0|  1|  1|  0|  1|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  2|  1|  0|  1|  0|  0|  0|  0|  0|  0|  1|  0|  0|  1|  0|  0|  1|  0|  0|  0|  2|  0|  0|  1|  0|  3|  0|  0|  0|  2|  4|  1|  0|   0|   7|   0|   1|   0|   0|   0|   0|   0|   0|   0|   4|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   1|   0|   4|   0|   0|   0|   0|   1|   0|   1|   0|   0|   0|   0|   0|   0|   1|   0|   1|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   1|   3|   0|   0|   0|   0|   0|   0|   1|   0|   0|\n",
      "|    1|  0|  0|  2|  1|  1|  0|  1|  0|  0|  0|  1|  0|  1|  0|  0|  1|  0|  5|  1|  0|  0|  1|  0|  0|  0|  1|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  1|  1|  0|  1|  0|  1|  0|  0|  0|  0|  0|  1|  0|  0|  1|  0|  2|  0|  0|  1|  0|  1|  0|  1|  0|  1|  0|  0|  1|  0|  2|  0|  0|   0|   3|   0|   0|   0|   0|   0|   0|   0|   0|   0|   2|   0|   0|   0|   1|   0|   0|   0|   1|   0|   0|   0|   0|   1|   0|   1|   0|   8|   0|   0|   0|   0|   0|   0|   1|   0|   0|   0|   0|   0|   0|   0|   1|   0|   0|   0|   0|   1|   0|   0|   0|   0|   0|   0|   0|   1|   1|   6|   0|   0|   0|   0|   0|   0|   1|   0|   1|\n",
      "|    1|  0|  1|  1|  0|  0|  1|  2|  0|  0|  0|  0|  0|  0|  1|  0|  0|  1|  6|  1|  1|  1|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  1|  0|  0|  1|  0|  0|  0|  0|  0|  0|  1|  1|  0|  0|  2|  0|  0|  0|  1|  0|  0|   1|  11|   0|   0|   0|   0|   0|   0|   0|   0|   1|   1|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   1|   0|   0|   0|   0|   4|   0|   0|   1|   0|   0|   1|   0|   0|   0|   1|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   1|   0|   0|   0|   1|   0|   0|   0|   0|  10|   0|   0|   0|   0|   0|   0|   0|   0|   0|\n",
      "|    3|  1|  0|  1|  3|  0|  0|  0|  2|  0|  0|  0|  0|  0|  0|  0|  0|  0| 10|  1|  0|  0|  0|  0|  1|  0|  1|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  2|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  1|  0|  0|  1|  2|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  1|  0|  1|  0|  0|  0|  0|  0|  2|  0|  0|   0|   6|   0|   1|   0|   1|   0|   0|   0|   0|   0|   0|   1|   0|   0|   0|   0|   0|   0|   0|   0|   1|   0|   0|   0|   0|   0|   0|   6|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   1|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   7|   0|   0|   0|   0|   0|   0|   0|   2|   2|\n",
      "|    3|  0|  0|  2|  0|  0|  0|  0|  1|  1|  0|  0|  0|  0|  0|  1|  0|  0|  5|  0|  0|  0|  1|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  3|  0|  2|  0|  0|  0|  0|  0|  0|  1|  1|  0|  0|  0|  0|  0|  0|  0|  1|  0|  2|  0|  1|  0|  0|  0|  0|  0|  2|  0|  2|  0|  0|   0|   4|   0|   1|   0|   0|   1|   0|   0|   0|   0|   3|   0|   1|   0|   0|   0|   0|   0|   0|   0|   1|   0|   0|   1|   0|   0|   0|   3|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   1|   0|   0|   0|   1|   1|   0|   0|   0|   0|   1|   0|   0|   0|   0|   5|   1|   0|   0|   0|   1|   0|   3|   0|   1|\n",
      "+-----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#this is what the final dataFrame looks like\n",
    "final_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from pyspark.ml.feature import StringIndexer\n",
    "# # build indexer\n",
    "# string_indexer = StringIndexer(inputCol='class', outputCol='in_class')\n",
    "\n",
    "# # learn the model\n",
    "# string_indexer_model = string_indexer.fit(final_df)\n",
    "\n",
    "# # transform the data\n",
    "# df_new = string_indexer_model.transform(final_df)\n",
    "\n",
    "# # resulting df\n",
    "# df_new.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class',\n",
       " 'x0',\n",
       " 'x1',\n",
       " 'x2',\n",
       " 'x3',\n",
       " 'x4',\n",
       " 'x5',\n",
       " 'x6',\n",
       " 'x7',\n",
       " 'x8',\n",
       " 'x9',\n",
       " 'x10',\n",
       " 'x11',\n",
       " 'x12',\n",
       " 'x13',\n",
       " 'x14',\n",
       " 'x15',\n",
       " 'x16',\n",
       " 'x17',\n",
       " 'x18',\n",
       " 'x19',\n",
       " 'x20',\n",
       " 'x21',\n",
       " 'x22',\n",
       " 'x23',\n",
       " 'x24',\n",
       " 'x25',\n",
       " 'x26',\n",
       " 'x27',\n",
       " 'x28',\n",
       " 'x29',\n",
       " 'x30',\n",
       " 'x31',\n",
       " 'x32',\n",
       " 'x33',\n",
       " 'x34',\n",
       " 'x35',\n",
       " 'x36',\n",
       " 'x37',\n",
       " 'x38',\n",
       " 'x39',\n",
       " 'x40',\n",
       " 'x41',\n",
       " 'x42',\n",
       " 'x43',\n",
       " 'x44',\n",
       " 'x45',\n",
       " 'x46',\n",
       " 'x47',\n",
       " 'x48',\n",
       " 'x49',\n",
       " 'x50',\n",
       " 'x51',\n",
       " 'x52',\n",
       " 'x53',\n",
       " 'x54',\n",
       " 'x55',\n",
       " 'x56',\n",
       " 'x57',\n",
       " 'x58',\n",
       " 'x59',\n",
       " 'x60',\n",
       " 'x61',\n",
       " 'x62',\n",
       " 'x63',\n",
       " 'x64',\n",
       " 'x65',\n",
       " 'x66',\n",
       " 'x67',\n",
       " 'x68',\n",
       " 'x69',\n",
       " 'x70',\n",
       " 'x71',\n",
       " 'x72',\n",
       " 'x73',\n",
       " 'x74',\n",
       " 'x75',\n",
       " 'x76',\n",
       " 'x77',\n",
       " 'x78',\n",
       " 'x79',\n",
       " 'x80',\n",
       " 'x81',\n",
       " 'x82',\n",
       " 'x83',\n",
       " 'x84',\n",
       " 'x85',\n",
       " 'x86',\n",
       " 'x87',\n",
       " 'x88',\n",
       " 'x89',\n",
       " 'x90',\n",
       " 'x91',\n",
       " 'x92',\n",
       " 'x93',\n",
       " 'x94',\n",
       " 'x95',\n",
       " 'x96',\n",
       " 'x97',\n",
       " 'x98',\n",
       " 'x99',\n",
       " 'x100',\n",
       " 'x101',\n",
       " 'x102',\n",
       " 'x103',\n",
       " 'x104',\n",
       " 'x105',\n",
       " 'x106',\n",
       " 'x107',\n",
       " 'x108',\n",
       " 'x109',\n",
       " 'x110',\n",
       " 'x111',\n",
       " 'x112',\n",
       " 'x113',\n",
       " 'x114',\n",
       " 'x115',\n",
       " 'x116',\n",
       " 'x117',\n",
       " 'x118',\n",
       " 'x119',\n",
       " 'x120',\n",
       " 'x121',\n",
       " 'x122',\n",
       " 'x123',\n",
       " 'x124',\n",
       " 'x125',\n",
       " 'x126',\n",
       " 'x127',\n",
       " 'x128',\n",
       " 'x129',\n",
       " 'x130',\n",
       " 'x131',\n",
       " 'x132',\n",
       " 'x133',\n",
       " 'x134',\n",
       " 'x135',\n",
       " 'x136',\n",
       " 'x137',\n",
       " 'x138',\n",
       " 'x139',\n",
       " 'x140',\n",
       " 'x141',\n",
       " 'x142',\n",
       " 'x143',\n",
       " 'x144',\n",
       " 'x145',\n",
       " 'x146',\n",
       " 'x147',\n",
       " 'x148',\n",
       " 'x149',\n",
       " 'x150',\n",
       " 'x151',\n",
       " 'x152',\n",
       " 'x153',\n",
       " 'x154',\n",
       " 'x155',\n",
       " 'x156',\n",
       " 'x157',\n",
       " 'x158',\n",
       " 'x159',\n",
       " 'x160',\n",
       " 'x161',\n",
       " 'x162',\n",
       " 'x163',\n",
       " 'x164',\n",
       " 'x165',\n",
       " 'x166',\n",
       " 'x167']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We consider the columns of the final DataFrame\n",
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this part of the code runs the Machine Learning Algorithm\n",
    "\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import ChiSqSelector\n",
    "from pyspark.ml.clustering import GaussianMixture\n",
    "\n",
    "#assemble all the festures in an assembler\n",
    "Cols= ['x'+ str(c) for c in range(0, 167)]\n",
    "Assembler = VectorAssembler ( inputCols = Cols, outputCol='features')\n",
    "\n",
    "#apply feature selection using Chisquared feature selection\n",
    "selector = ChiSqSelector(numTopFeatures=13, featuresCol='features',outputCol='selectedFeatures', labelCol='class')\n",
    "\n",
    "gmm = GaussianMixture(featuresCol='selectedFeatures', predictionCol = 'prediction', k= 4, probabilityCol='probability', maxIter= 100, seed=1) \n",
    "pipeline = Pipeline(stages=[Assembler, selector,gmm])\n",
    "\n",
    "(train, test) = final_df.randomSplit([0.7, 0.3])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = pipeline.fit(train)\n",
    "# result = model.transform(final_df).select('features', 'selectedFeatures', 'probability', 'prediction', 'class')\n",
    "# result.show(3200)\n",
    "# d = result.select('prediction', 'class').toPandas()\n",
    "# d.loc[d['class'] == 1, 'prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the test data is fit into the model\n",
    "model123 = pipeline.fit(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we select just a couple of features from the entire dataset\n",
    "result123 = model123.transform(final_df).select('features', 'selectedFeatures', 'probability','prediction', 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+-----+\n",
      "|            features|    selectedFeatures|         probability|prediction|class|\n",
      "+--------------------+--------------------+--------------------+----------+-----+\n",
      "|(167,[0,2,14,15,1...|(13,[0,1,3,10,11,...|[8.93434956670095...|         1|    1|\n",
      "|(167,[2,3,4,6,10,...|(13,[0,1,2,5,10,1...|[1.05446865791479...|         1|    1|\n",
      "|(167,[1,2,5,6,13,...|(13,[0,2,4,6,8,10...|[0.00168771377131...|         3|    1|\n",
      "|(167,[0,2,3,7,17,...|(13,[0,1,2,6,7,10...|[1.75388052937046...|         1|    3|\n",
      "|(167,[2,7,8,14,17...|(13,[0,6,10,11,12...|[1.63410665303511...|         1|    3|\n",
      "+--------------------+--------------------+--------------------+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#in here we see how features contains 168 features out of which only 13 features are selected\n",
    "result123.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PipelineModel' object has no attribute 'select'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-65b9daa82b98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0md123\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel123\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'prediction'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'class'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0md123\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'PipelineModel' object has no attribute 'select'"
     ]
    }
   ],
   "source": [
    "d123 = model123.select('prediction', 'class').toPandas()\n",
    "d123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a class matrix to check the accuracy\n",
    "pospos = 0\n",
    "negneg = 0\n",
    "posneg = 0\n",
    "negpos = 0\n",
    "for iterator in range(len(d123)):\n",
    "    if d123['prediction'][iterator] != d123['class'][iterator]:\n",
    "        if d123['class'][iterator] == 0:\n",
    "            pospos = pospos + 1\n",
    "        if d123['class'][iterator] == 1:\n",
    "            negneg = negneg + 1\n",
    "    else:\n",
    "        if d123['class'][iterator] == 0:\n",
    "            posneg = posneg + 1\n",
    "        if d123['class'][iterator] == 1:\n",
    "            negpos = negpos + 1\n",
    "\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "print(\"Finished making predictions for test data.\\n\")\n",
    "print(\"x-axis: predicted class\")\n",
    "print(\"y-axis: actual class\")\n",
    "print(\"\\n\")\n",
    "print(\"\\tcls pos\\tneg\")\n",
    "print(\"\\tpos\", pospos,posneg)\n",
    "print(\"\\tneg\", negpos,negneg)\n",
    "\n",
    "accuracy = (pospos+negneg)/(pospos+negneg+posneg+negpos)*100\n",
    "print(\"\\nAccuracy of the model : \", accuracy,\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res123 = []\n",
    "for i in range(len(d123)):\n",
    "    if d123['prediction'][i] == 1:\n",
    "        res123.append(0)\n",
    "    else:\n",
    "        res123.append(1)\n",
    "        \n",
    "test123 = []\n",
    "for i in range(len(d123)):\n",
    "    test123.append(d123['class'][i])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a confusion matrix\n",
    "\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "LABELS = {\"Normal ECG\", \"Abnormal ECG\", \"C\", \"D\"}\n",
    "n_classes = 4\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "confusion_matrix = metrics.confusion_matrix(test123, res123)\n",
    "print(confusion_matrix)\n",
    "normalised_confusion_matrix = np.array(confusion_matrix, dtype=np.float32)/np.sum(confusion_matrix)*100\n",
    "\n",
    "print(\"\")\n",
    "print(\"Confusion matrix (normalised to % of total test data):\")\n",
    "print(normalised_confusion_matrix)\n",
    "print(\"Note: training and testing data is not equally distributed amongst classes, \")\n",
    "print(\"so it is normal that more than a 6th of the data is correctly classifier in the last category.\")\n",
    "\n",
    "# Plot Results: \n",
    "width = 5\n",
    "height = 5\n",
    "plt.figure(figsize=(width, height))\n",
    "plt.imshow(\n",
    "    normalised_confusion_matrix, \n",
    "    interpolation='nearest', \n",
    "    cmap=plt.cm.rainbow\n",
    ")\n",
    "plt.title(\"Confusion matrix \\n(normalised to % of total test data)\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(n_classes)\n",
    "\n",
    "plt.xticks(tick_marks, LABELS, rotation=90)\n",
    "plt.yticks(tick_marks, LABELS)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
