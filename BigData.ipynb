{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of ECG BigData using PyStark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these characters are used as part of the compression algorithm\n",
    "\n",
    "gsm = list(r'@£$¥èéùìòÇØøÅå_^{}[~]|€ӔӕßÉ!#¤%&()*+,-./:;<?¡§¿äöñüàÀÁÂÃÄÈÊËÌÍÎÏÐÑÒÓÔÕÖÙÚÛÜÝÞþáâãçêëíîïðóôõúûýabcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "gsm.append(\"\\\\\")\n",
    "range_list = [0, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, 1000]\n",
    "for i in range_list:\n",
    "    gsm.append(\"Num\"+str(i))\n",
    "\n",
    "gsm.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the encode function compresses an ECG segment(in numerical format) to an alphanumeric value\n",
    "from queue import Queue\n",
    "import math\n",
    "def encode(lines):\n",
    "    \n",
    "    q = Queue()\n",
    "    for j in map(int,lines.split(',')):\n",
    "        q.put(j)\n",
    "    \n",
    "    print(q)\n",
    "    \n",
    "    noOfSmpl = 1\n",
    "    intDiff = []\n",
    "    endOfEcg = False\n",
    "    rrOn = True\n",
    "    rrCount = 0\n",
    "    ecgSmpl1 = q.get()\n",
    "    rrComp1 = 0\n",
    "    encSB = []\n",
    "    rrSB = []\n",
    "    gsm = list(\n",
    "        r'@£$¥èéùìòÇØøÅå_^{}[~]|€ӔӕßÉ!#¤%&()*+,-./:;<?¡§¿äöñüàÀÁÂÃÄÈÊËÌÍÎÏÐÑÒÓÔÕÖÙÚÛÜÝÞþáâãçêëíîïðóôõúûýabcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "    gsm.append(\"\\\\\")\n",
    "\n",
    "\n",
    "    intHrv = 0\n",
    "    while endOfEcg != True and not q.empty():\n",
    "\n",
    "        intDiff = [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        for i in range(0, 8):\n",
    "            ecgSmpl2 = q.get()\n",
    "            noOfSmpl = noOfSmpl + 1\n",
    "            diff = ecgSmpl2 - ecgSmpl1\n",
    "\n",
    "            try:\n",
    "                if (math.ceil(diff) - diff) > 0.5:\n",
    "                    intDiff[i] = int(math.floor(diff))  # there was an (int) here\n",
    "                else:\n",
    "                    intDiff[i] = int(math.ceil(diff))\n",
    "            except:\n",
    "                print(\"ERROR\", intDiff[i], math.floor(diff))\n",
    "\n",
    "            ecgSmpl1 = ecgSmpl2\n",
    "\n",
    "        if q.empty():\n",
    "            endOfEcg = True\n",
    "\n",
    "        # intDiff is a list of 8 elements\n",
    "        signVal = 0\n",
    "\n",
    "        for i in range(0, 8):\n",
    "            if intDiff[i] <= -1:\n",
    "                if i == 0:\n",
    "                    signVal = signVal + 1\n",
    "                elif i == 1:\n",
    "                    signVal = signVal + 2\n",
    "                elif i == 2:\n",
    "                    signVal = signVal + 4\n",
    "                elif i == 3:\n",
    "                    signVal = signVal + 8\n",
    "                elif i == 4:\n",
    "                    signVal = signVal + 16\n",
    "                elif i == 5:\n",
    "                    signVal = signVal + 32\n",
    "                elif i == 6:\n",
    "                    signVal = signVal + 64\n",
    "                elif i == 7:\n",
    "                    encSB.append('')\n",
    "\n",
    "                intDiff[i] = abs(intDiff[i])\n",
    "\n",
    "        encSB.append(gsm[signVal])\n",
    "\n",
    "\n",
    "        # for q = 7\n",
    "        for i in range(0, 7, 2):\n",
    "            # compresses two single digits as one\n",
    "            if (intDiff[i] < 10) and (intDiff[i + 1] < 10):\n",
    "                join = intDiff[i] * 10 + intDiff[i + 1]\n",
    "                encSB.append(gsm[join])\n",
    "            # compresses all values less than 147\n",
    "            elif (intDiff[i] < 47) and (intDiff[i + 1] < 47):\n",
    "                encSB.append(gsm[intDiff[i] + 100])\n",
    "                encSB.append(gsm[intDiff[i + 1] + 100])\n",
    "            else:\n",
    "                encSB.append(str(intDiff[i]))\n",
    "                encSB.append('\"')\n",
    "                encSB.append(str(intDiff[i + 1]))\n",
    "                encSB.append('\"')\n",
    "                # rr detection proceeding\n",
    "                if rrOn == True:\n",
    "                    if (rrComp1 < intDiff[i]) and (intDiff[i] < intDiff[i + 1]):\n",
    "                        rrComp1 = intDiff[i + 1]\n",
    "                    else:\n",
    "                        if rrComp1 < intDiff[i]:\n",
    "                            rrCount = rrCount - 1\n",
    "                        rrVal = float(rrCount)\n",
    "                        rrVal = rrVal / 360\n",
    "                        rrSB.append(rrVal)\n",
    "                        rrCount = 0\n",
    "                        rrOn = False\n",
    "                        intHrv = intHrv + 1\n",
    "\n",
    "    str_encSB = ''.join(encSB)\n",
    "\n",
    "    return str_encSB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this function derives the features from a compressed ECG segment\n",
    "\n",
    "def compress(segment):\n",
    "    i = 0\n",
    "    range_list = [0, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, 1000]\n",
    "    alpha_count = {}\n",
    "    while i < len(segment):\n",
    "\n",
    "        if segment[i].isdigit():\n",
    "\n",
    "            s = ''\n",
    "            while (segment[i] != '\"'):\n",
    "                s = s + segment[i]\n",
    "                i = i + 1\n",
    "\n",
    "            for g in range(len(range_list)):\n",
    "                if int(s) <= range_list[g]:\n",
    "                    t = \"Num\" + str(g)\n",
    "                    break\n",
    "\n",
    "            if t not in alpha_count.keys():\n",
    "                alpha_count[t] = 1\n",
    "            else:\n",
    "                alpha_count[t] = alpha_count[t] + 1\n",
    "\n",
    "\n",
    "        else:\n",
    "            s = segment[i]\n",
    "            if s not in alpha_count.keys():\n",
    "                alpha_count[s] = 1\n",
    "            else:\n",
    "                alpha_count[s] = alpha_count[s] + 1\n",
    "\n",
    "        i = i + 1\n",
    "\n",
    "\n",
    "    output = []\n",
    "    for val in gsm:\n",
    "        if val in alpha_count.keys():\n",
    "            output.append(alpha_count[val])\n",
    "        else:\n",
    "            output.append(0)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The main program starts from here\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import SparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#defining a spark session\n",
    "spark = SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all the data is loaded in an RDD at once\n",
    "rdd = sc.textFile(r'C:\\Users\\Shweta\\PycharmProjects\\untitled\\new_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3,4,5,9,8,8,7,3,3,2,3,2,2,1,2,1,0,1,1,2,2,1,2,2,2,1,2,1,1,3,3,0,6,13,37,55,77,98,110,112,103,85,56,18,15,45,93,111,116,114,102,85,65,36,21,12,8,7,6,5,5,3,4,3,3,1,1,2,5,5,5,5,6,7,7,8,9,8,8,8,7,6,6,5,4,5,7,6,8,7,8,10,12,15,13,12,13']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is what one line of the data looks like\n",
    "rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kø;£:îøØøø{ØØø@ÕøØ],@nEyCBs¤^yJSj30\"48\"ylHisxAJvaðøØ|Ø£]å@£{ØøØ£þØøÅÅdø€(ø',\n",
       " 'Ð@££Ø{@Ø]|Ò£@£]¥|Ø|$@ìyMsp|_}PKkTNpH*,rQIi^;|Å£,Ø]£ØÅ£ø@@ò£øø@øÅ$ø£',\n",
       " 'c&ÉÒ<E$<|%,@øøÃÍüÅ|ӕ@lFuyCGulì24\"53\"Mn49\"54\"JjbzV\\\\Hänq¥§¥ø@a||Ø]$øØ@£òØ£øӔÀ*|ÃØ',\n",
       " 'A$£€ø@£&]@âøÅ@]òØÅ@€@mrrxCECu_gu46\"48\"3\"57\"76\"33\"ÏhH48\"69\"KxüDÅum€ÊáÉøØÅßå£|Åìø%$|ù£]Å]',\n",
       " 'c@ø£|{(@|Ø§Øøøå¿*|Å#@yswxvwtn^lC61\"29\"70\"70\"SnH28\"51\"60\"38\"íØ-ØØ£@þÅøÅø¡ê;$£;Ø£øø@ØØ]*']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now the encode function is mapped to each line of the RDD\n",
    "data1 = rdd.map(encode)\n",
    "data1.take(5)             #we have shown 5 lines of compressed ECG signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 3, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 2, 0, 0, 1, 0, 1, 3, 0, 2, 1, 0, 0, 0, 4, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 1, 0, 0, 1]\n",
      "[0, 0, 2, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 5, 1, 0, 0, 9, 0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 2, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 2, 0, 4, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 1, 1, 0, 5, 0, 0, 0, 2, 0, 2, 1, 0, 1, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0]\n",
      "[0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 1, 0, 2, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 3, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 4, 1, 0, 0, 1, 0, 0, 0, 0, 3]\n",
      "[0, 1, 1, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 0, 2, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 1, 0, 1, 2, 1, 1, 0, 1, 3, 0, 0, 1, 4, 0, 0, 1, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# now features are derived from each line of the RDD\n",
    "data2 = data1.map(compress)\n",
    "temp = data2.take(5)           #we have shown features derived from 5 ECG segments\n",
    "\n",
    "for i in temp:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '#', '$', '%', '&', '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'Num0', 'Num100', 'Num1000', 'Num150', 'Num200', 'Num250', 'Num300', 'Num350', 'Num400', 'Num450', 'Num50', 'Num500', 'Num550', 'Num600', 'Num650', 'Num700', 'Num750', 'Num800', 'Num850', 'Num900', 'Num950', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', '¡', '£', '¤', '¥', '§', '¿', 'À', 'Á', 'Â', 'Ã', 'Ä', 'Å', 'Ç', 'È', 'É', 'Ê', 'Ë', 'Ì', 'Í', 'Î', 'Ï', 'Ð', 'Ñ', 'Ò', 'Ó', 'Ô', 'Õ', 'Ö', 'Ø', 'Ù', 'Ú', 'Û', 'Ü', 'Ý', 'Þ', 'ß', 'à', 'á', 'â', 'ã', 'ä', 'å', 'ç', 'è', 'é', 'ê', 'ë', 'ì', 'í', 'î', 'ï', 'ð', 'ñ', 'ò', 'ó', 'ô', 'õ', 'ö', 'ø', 'ù', 'ú', 'û', 'ü', 'ý', 'þ', 'Ӕ', 'ӕ', '€']\n"
     ]
    }
   ],
   "source": [
    "#these are the indivisual features we shall be looking for\n",
    "keys = gsm\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now we create a DataFrame from our RDD\n",
    "a = sqlContext.createDataFrame(data2, ['x'+str(i) for i in range(0,len(keys))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is the schema of the DataFrame\n",
    "#a.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We take the class of the input features in a list\n",
    "fz = open(r'C:\\Users\\Shweta\\PycharmProjects\\untitled\\new_output_class.txt', 'r')\n",
    "cls = fz.read()\n",
    "fz.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# c = 0\n",
    "# for i in cls.split(','):\n",
    "#     if i != '':\n",
    "#         c += 1\n",
    "# print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we create another DataFrame consisting of only class column\n",
    "b = sqlContext.createDataFrame([(int(i),) for i in cls.split(',') if i != ''], ['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(class,LongType,true)))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we consider the schema of the class column\n",
    "b.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now we join the two dataframes(for features and class) togeather in the final dataFrame\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "a = a.withColumn(\"row_idx\", monotonically_increasing_id())\n",
    "b = b.withColumn(\"row_idx\", monotonically_increasing_id())\n",
    "final_df = b.join(a, b.row_idx == a.row_idx).drop(\"row_idx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "|class| x0| x1| x2| x3| x4| x5| x6| x7| x8| x9|x10|x11|x12|x13|x14|x15|x16|x17|x18|x19|x20|x21|x22|x23|x24|x25|x26|x27|x28|x29|x30|x31|x32|x33|x34|x35|x36|x37|x38|x39|x40|x41|x42|x43|x44|x45|x46|x47|x48|x49|x50|x51|x52|x53|x54|x55|x56|x57|x58|x59|x60|x61|x62|x63|x64|x65|x66|x67|x68|x69|x70|x71|x72|x73|x74|x75|x76|x77|x78|x79|x80|x81|x82|x83|x84|x85|x86|x87|x88|x89|x90|x91|x92|x93|x94|x95|x96|x97|x98|x99|x100|x101|x102|x103|x104|x105|x106|x107|x108|x109|x110|x111|x112|x113|x114|x115|x116|x117|x118|x119|x120|x121|x122|x123|x124|x125|x126|x127|x128|x129|x130|x131|x132|x133|x134|x135|x136|x137|x138|x139|x140|x141|x142|x143|x144|x145|x146|x147|x148|x149|x150|x151|x152|x153|x154|x155|x156|x157|x158|x159|x160|x161|x162|x163|x164|x165|x166|x167|\n",
      "+-----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "|    1|  1|  0|  2|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  1|  0|  6|  1|  1|  0|  0|  1|  1|  0|  1|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  2|  1|  0|  1|  0|  0|  0|  0|  0|  0|  1|  0|  0|  1|  0|  0|  1|  0|  0|  0|  2|  0|  0|  1|  0|  3|  0|  0|  0|  2|  4|  1|  0|   0|   7|   0|   1|   0|   0|   0|   0|   0|   0|   0|   4|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   1|   0|   4|   0|   0|   0|   0|   1|   0|   1|   0|   0|   0|   0|   0|   0|   1|   0|   1|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   0|   1|   3|   0|   0|   0|   0|   0|   0|   1|   0|   0|\n",
      "|    1|  0|  0|  2|  1|  1|  0|  1|  0|  0|  0|  1|  0|  1|  0|  0|  1|  0|  5|  1|  0|  0|  1|  0|  0|  0|  1|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  1|  1|  0|  1|  0|  1|  0|  0|  0|  0|  0|  1|  0|  0|  1|  0|  2|  0|  0|  1|  0|  1|  0|  1|  0|  1|  0|  0|  1|  0|  2|  0|  0|   0|   3|   0|   0|   0|   0|   0|   0|   0|   0|   0|   2|   0|   0|   0|   1|   0|   0|   0|   1|   0|   0|   0|   0|   1|   0|   1|   0|   8|   0|   0|   0|   0|   0|   0|   1|   0|   0|   0|   0|   0|   0|   0|   1|   0|   0|   0|   0|   1|   0|   0|   0|   0|   0|   0|   0|   1|   1|   6|   0|   0|   0|   0|   0|   0|   1|   0|   1|\n",
      "+-----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#this is what the final dataFrame looks like\n",
    "final_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from pyspark.ml.feature import StringIndexer\n",
    "# # build indexer\n",
    "# string_indexer = StringIndexer(inputCol='class', outputCol='in_class')\n",
    "\n",
    "# # learn the model\n",
    "# string_indexer_model = string_indexer.fit(final_df)\n",
    "\n",
    "# # transform the data\n",
    "# df_new = string_indexer_model.transform(final_df)\n",
    "\n",
    "# # resulting df\n",
    "# df_new.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We consider the columns of the final DataFrame\n",
    "#final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this part of the code runs the Machine Learning Algorithm\n",
    "\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import ChiSqSelector\n",
    "from pyspark.ml.clustering import GaussianMixture\n",
    "\n",
    "#assemble all the festures in an assembler\n",
    "Cols= ['x'+ str(c) for c in range(0, 167)]\n",
    "Assembler = VectorAssembler ( inputCols = Cols, outputCol='features')\n",
    "\n",
    "#apply feature selection using Chisquared feature selection\n",
    "selector = ChiSqSelector(numTopFeatures=13, featuresCol='features',outputCol='selectedFeatures', labelCol='class')\n",
    "\n",
    "gmm = GaussianMixture(featuresCol='selectedFeatures', predictionCol = 'prediction', k= 4, probabilityCol='probability', maxIter= 100, seed=1) \n",
    "pipeline = Pipeline(stages=[Assembler, selector,gmm])\n",
    "\n",
    "(train, test) = final_df.randomSplit([0.7, 0.3])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = pipeline.fit(train)\n",
    "# result = model.transform(final_df).select('features', 'selectedFeatures', 'probability', 'prediction', 'class')\n",
    "# result.show(3200)\n",
    "# d = result.select('prediction', 'class').toPandas()\n",
    "# d.loc[d['class'] == 1, 'prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the test data is fit into the model\n",
    "model123 = pipeline.fit(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we select just a couple of features from the entire dataset\n",
    "result123 = model123.transform(final_df).select('features', 'selectedFeatures', 'probability','prediction', 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+-----+\n",
      "|            features|    selectedFeatures|         probability|prediction|class|\n",
      "+--------------------+--------------------+--------------------+----------+-----+\n",
      "|(167,[0,2,14,15,1...|(13,[0,1,5,10,11,...|[3.72449968684894...|         1|    1|\n",
      "|(167,[2,3,4,6,10,...|(13,[0,4,6,10,11,...|[6.96743265451260...|         3|    1|\n",
      "|(167,[1,2,5,6,13,...|(13,[0,2,7,9,10,1...|[1.54453813142484...|         1|    1|\n",
      "|(167,[0,2,3,7,17,...|(13,[0,1,3,7,8,10...|[0.99892350420316...|         0|    3|\n",
      "|(167,[2,7,8,14,17...|(13,[0,1,5,7,10,1...|[1.56155953605912...|         1|    3|\n",
      "+--------------------+--------------------+--------------------+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#in here we see how features contains 168 features out of which only 13 features are selected\n",
    "result123.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "d123 = result123.select('prediction', 'class').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction  class\n",
       "0           1      1\n",
       "1           3      1\n",
       "2           1      1\n",
       "3           0      3\n",
       "4           1      3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d123[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Finished making predictions for test data.\n",
      "\n",
      "x-axis: predicted class\n",
      "y-axis: actual class\n",
      "\n",
      "\n",
      "\tcls pos\tneg\n",
      "\tpos 4478 746\n",
      "\tneg 44090 75925\n",
      "\n",
      "Accuracy of the model :  64.19965026868627 %\n"
     ]
    }
   ],
   "source": [
    "#build a class matrix to check the accuracy\n",
    "pospos = 0\n",
    "negneg = 0\n",
    "posneg = 0\n",
    "negpos = 0\n",
    "for iterator in range(len(d123)):\n",
    "    if d123['prediction'][iterator] != d123['class'][iterator]:\n",
    "        if d123['class'][iterator] == 0:\n",
    "            pospos = pospos + 1\n",
    "        if d123['class'][iterator] == 1:\n",
    "            negneg = negneg + 1\n",
    "    else:\n",
    "        if d123['class'][iterator] == 0:\n",
    "            posneg = posneg + 1\n",
    "        if d123['class'][iterator] == 1:\n",
    "            negpos = negpos + 1\n",
    "\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "print(\"Finished making predictions for test data.\\n\")\n",
    "print(\"x-axis: predicted class\")\n",
    "print(\"y-axis: actual class\")\n",
    "print(\"\\n\")\n",
    "print(\"\\tcls pos\\tneg\")\n",
    "print(\"\\tpos\", pospos,posneg)\n",
    "print(\"\\tneg\", negpos,negneg)\n",
    "\n",
    "accuracy = (pospos+negneg)/(pospos+negneg+posneg+negpos)*100\n",
    "print(\"\\nAccuracy of the model : \", accuracy,\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
